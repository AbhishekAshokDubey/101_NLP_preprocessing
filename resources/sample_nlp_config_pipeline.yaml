readfile:
    path: 'C:\Users\Adubey4\Desktop\nlp\datasets\small.csv'
    column_info: content # column name/ number
stopword_removal:
    stopwords_file_path: 'C:\Users\Adubey4\Desktop\git\101_NLP_preprocessing\resources\sample_extra_stopword.csv'
    append_to_default_list: False
    remove_punctuation: true
spell_correction:
    spell_corrector_type : autocorrect # options: autocorrect, hunspell
    spell_list_hunspell : 'C:\Users\Adubey4\Desktop\pychant\dict-en'
dict_replacement:
    regex_dict_path : 'C:\Users\Adubey4\Desktop\text_preProces\nlpslb\resources\sample_regex_dict.csv'
    word_dict_path : 'C:\Users\Adubey4\Desktop\text_preProces\nlpslb\resources\sample_word_dict.csv'
stemming:
    stemmertype: porter # options: porter, lancaster
lemmatizer:
    lemmatizertype : wordnet # options: wordnet
postagging:
    tagger: nltk
word2vec_model:
    word2vec_algo: gensim
    train_textcorpus: brown # options: 'samedata', 'brown', 'movie_reviews', 'treebank' corpus from nltk corpus
doc2vec_model:
    doc2vec_algo: gensim
summarization:
    type: doc_vec # options: doc_vec & word_freq
    sent_len: 1
pipeline:
    stopword_removal: 1 # No operation is 0, First operation is 1, Second operation is 2 and so on
    spell_correction: 2
    dict_replacement: 0
    stemming: 0
    lemmatizer: 0
    postagging: 0
    word2vec_model: 3
    doc2vec_model: 0
    summarization: 0